{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzbn4tbt8XKEpfhObQTCSO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BehnoodRasti/Unmixing_Tutorial_IEEE_IADF/blob/main/UnDIP_Colab_Apex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BehnoodRasti/UnDIP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DX-laLkPbxL",
        "outputId": "ae22bcfa-5e02-4225-b7dd-9eb8eb0c413f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UnDIP'...\n",
            "remote: Enumerating objects: 173, done.\u001b[K\n",
            "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 173 (delta 71), reused 163 (delta 64), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (173/173), 21.72 MiB | 33.55 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t2NBPwzaO1KP"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Apr  1 09:23:20 2021\n",
        "@author: behnood\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "\n",
        "import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
        "\n",
        "import numpy as np\n",
        "from UnDIP.models import *\n",
        "\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "#from skimage.measure import compare_psnr\n",
        "#from skimage.measure import compare_mse\n",
        "from UnDIP.utils.denoising_utils import *\n",
        "\n",
        "from skimage._shared import *\n",
        "from skimage.util import *\n",
        "from skimage.metrics.simple_metrics import _as_floats\n",
        "from skimage.metrics.simple_metrics import mean_squared_error\n",
        "\n",
        "from UnDIP.UtilityMine import *\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "PLOT = True\n",
        "#%% Load image\n",
        "import scipy.io\n",
        "#%%\n",
        "fname2  = \"UnDIP/Data/Samson/Y_clean.mat\"\n",
        "mat2 = scipy.io.loadmat(fname2)\n",
        "img_np_gt = mat2[\"Y_clean\"]\n",
        "img_np_gt = img_np_gt.transpose(2,0,1)\n",
        "[p1, nr1, nc1] = img_np_gt.shape\n",
        "#%%\n",
        "fname3  = \"UnDIP/Data/Samson/A_true.mat\"\n",
        "mat3 = scipy.io.loadmat(fname3)\n",
        "A_true_np = mat3[\"A_true\"]\n",
        "A_true_np = A_true_np.transpose(2,0,1)\n",
        "#%%\n",
        "fname4  = \"UnDIP/Data/Samson/E.mat\"\n",
        "mat4 = scipy.io.loadmat(fname4)\n",
        "E_np = mat4[\"E\"]\n",
        "n_lin=50\n",
        "E_Lin=np.zeros((1,n_lin))\n",
        "E_Lin[0,:]=np.linspace(0.5,1.5,n_lin)\n",
        "rmax=E_np.shape[1]\n",
        "EE=np.zeros((p1,rmax*n_lin))\n",
        "\n",
        "#%%\n",
        "import matplotlib.pyplot as plt\n",
        "npar=np.zeros((1,4))\n",
        "npar[0,0]=41\n",
        "npar[0,1]=129\n",
        "npar[0,2]=410\n",
        "npar[0,3]=600\n",
        "tol1=npar.shape[1]\n",
        "tol2=5\n",
        "Metric=np.zeros((tol2,10,tol1))\n",
        "#mse_E=np.zeros((tol1,tol2))\n",
        "save_result=False\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for fi in tqdm(range(tol1)):\n",
        "    for fj in tqdm(range(tol2)):\n",
        "            #%%\n",
        "        #img_noisy_np = get_noisy_image(img_np_gt, 1/10)\n",
        "        img_noisy_np = add_noise(img_np_gt, 1/npar[0,fi])#11.55 20 dB, 36.7 30 dB, 116.5 40 dB\n",
        "        print(compare_snr(img_np_gt, img_noisy_np))\n",
        "        img_resh=np.reshape(img_noisy_np,(p1,nr1*nc1))\n",
        "        V, SS, U = scipy.linalg.svd(img_resh, full_matrices=False)\n",
        "        PC=np.diag(SS)@U\n",
        "        img_resh_DN=V[:,:rmax]@PC[:rmax,:]\n",
        "        img_resh_np_clip=np.clip(img_resh_DN, 0, 1)\n",
        "        II,III = Endmember_extract(img_resh_np_clip,rmax)\n",
        "        E_np1=img_resh_np_clip[:,II]\n",
        "        #asq=Endmember_reorder2(E_np,E_np1)\n",
        "        #asq1=rmax-1-asq\n",
        "        #E_np1=E_np1[:,asq]  \n",
        "        #%% Set up Simulated \n",
        "        INPUT = 'noise' # 'meshgrid'\n",
        "        pad = 'reflection'\n",
        "        need_bias=True\n",
        "        OPT_OVER = 'net' # 'net,input'\n",
        "        \n",
        "        # \n",
        "        reg_noise_std = 0.0# 1/100# 1./30. # set to 1./20. for sigma=50\n",
        "        LR1 = 0.001\n",
        "        \n",
        "        OPTIMIZER1='adam' # 'RMSprop'#'adam' # 'LBFGS'\n",
        "        show_every = 100\n",
        "        exp_weight=0.99\n",
        "        \n",
        "        num_iter1 = 3000\n",
        "        input_depth = rmax#img_noisy_np.shape[0]\n",
        "        class CAE_AbEst(nn.Module):\n",
        "            def __init__(self):\n",
        "                super(CAE_AbEst, self).__init__()\n",
        "                # encoding layers\n",
        "                self.conv1 = nn.Sequential(\n",
        "                     UnmixArch(\n",
        "                            input_depth, rmax,\n",
        "                            # num_channels_down = [8, 16, 32, 64, 128], \n",
        "                            # num_channels_up   = [8, 16, 32, 64, 128],\n",
        "                            # num_channels_skip = [4, 4, 4, 4, 4], \n",
        "                            num_channels_down = [ 256],\n",
        "                            num_channels_up =   [ 256],\n",
        "                            num_channels_skip =    [ 4],  \n",
        "                            filter_size_up = 3,filter_size_down = 3,  filter_skip_size=1,\n",
        "                            upsample_mode='bilinear', # downsample_mode='avg',\n",
        "                            need1x1_up=True,\n",
        "                            need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "                )\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = self.conv1(x)\n",
        "\n",
        "                return x\n",
        "\n",
        "        net1 = CAE_AbEst()\n",
        "        net1.cuda()\n",
        "        print(net1)\n",
        "\n",
        "        # Compute number of parameters\n",
        "        s  = sum([np.prod(list(p11.size())) for p11 in net1.parameters()]); \n",
        "        print ('Number of params: %d' % s)\n",
        "        \n",
        "        # Loss\n",
        "        mse = torch.nn.MSELoss().type(dtype)\n",
        "        img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)\n",
        "        # if fk==0:\n",
        "        net_input1 = get_noise(input_depth, INPUT,\n",
        "          (img_noisy_np.shape[1], img_noisy_np.shape[2])).type(dtype).detach()\n",
        "        E_torch = np_to_torch(E_np1).type(dtype)\n",
        "        #\n",
        "        A_true_np_resh=A_true_np.reshape(A_true_np.shape[0],A_true_np.shape[1]*A_true_np.shape[2])\n",
        "        #%%\n",
        "        net_input_saved = net_input1.detach().clone()\n",
        "        noise = net_input1.detach().clone()\n",
        "        out_avg = None\n",
        "        out_HR_avg= None\n",
        "        last_net = None\n",
        "        RMSE_LR_last = 0\n",
        "        \n",
        "        i = 0\n",
        "        def closure1():\n",
        "            \n",
        "            global i, RMSE_LR, RMSE_LR_ave, RMSE_HR, out_LR_np, out_avg_np, out_LR\\\n",
        "                , out_avg,out_HR_np, out_HR_avg, out_HR_avg_np, RMSE_LR_last, last_net\\\n",
        "                    , net_input,RMSE_LR_avg,RMSE_HR_avg,RE_HR_avg, RE_HR, Eest\\\n",
        "                        , MAE_LR,MAE_LR_avg,MAE_HR,MAE_HR_avg\n",
        "            \n",
        "            if reg_noise_std > 0:\n",
        "                net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "            \n",
        "            out_LR = net1(net_input1)\n",
        "            out_HR=torch.mm(E_torch.view(p1,rmax),out_LR.view(rmax,nr1*nc1))\n",
        "            # Smoothing\n",
        "            if out_avg is None:\n",
        "                out_avg = out_LR.detach()\n",
        "                out_HR_avg = out_HR.detach()\n",
        "            else:\n",
        "                out_avg = out_avg * exp_weight + out_LR.detach() * (1 - exp_weight)\n",
        "                out_HR_avg = out_HR_avg * exp_weight + out_HR.detach() * (1 - exp_weight)\n",
        "              \n",
        "        #%%\n",
        "            out_HR=out_HR.view((1,p1,nr1,nc1))\n",
        "            total_loss = mse(img_noisy_torch, out_HR)\n",
        "            total_loss.backward()\n",
        "        \n",
        "         \n",
        "        \n",
        "            out_LR_np = out_LR.detach().cpu().squeeze().numpy()\n",
        "            out_avg_np = out_avg.detach().cpu().squeeze().numpy()\n",
        "            out_HR_np = out_HR.detach().cpu().squeeze().numpy()\n",
        "           # out_HR_avg=out_HR_avg.view((1,p1,nr1,nc1))\n",
        "            out_HR_avg_np = out_HR_avg.detach().cpu().squeeze().numpy()\n",
        "            RMSE_LR = 100*np.sqrt(compare_mse(A_true_np.astype(np.float32), np.clip(out_LR_np, 0, 1)))\n",
        "            RMSE_LR_avg   = 100*np.sqrt(compare_mse(A_true_np.astype(np.float32), np.clip(out_avg_np, 0, 1)))\n",
        "            RMSE_HR= 100*np.sqrt(compare_mse(img_np_gt.astype(np.float32), np.clip(out_HR_np, 0, 1)))\n",
        "            RMSE_HR_avg= 100*np.sqrt(compare_mse(img_np_gt.astype(np.float32).reshape((p1,nr1*nc1)), np.clip(out_HR_avg_np, 0, 1)))\n",
        "            MAE_LR= 100*np.mean(abs(A_true_np.astype(np.float32)- np.clip(out_LR_np, 0, 1)))\n",
        "            MAE_HR= 100*np.mean(abs(img_np_gt.astype(np.float32)- np.clip(out_HR_np, 0, 1)))\n",
        "            MAE_LR_avg= 100*np.mean(abs(A_true_np.astype(np.float32)- np.clip(out_avg_np, 0, 1)))\n",
        "            MAE_HR_avg= 100*np.mean(abs(img_np_gt.astype(np.float32).reshape((p1,nr1*nc1))- np.clip(out_HR_avg_np, 0, 1)))\n",
        "            \n",
        "            \n",
        "            RE_HR= 100*np.sqrt(compare_mse(img_noisy_np.astype(np.float32), np.clip(out_HR_np, 0, 1)))\n",
        "            RE_HR_avg= 100*np.sqrt(compare_mse(img_noisy_np.astype(np.float32).reshape((p1,nr1*nc1)), np.clip(out_HR_avg_np, 0, 1)))\n",
        "\n",
        "            # Note that we do not have GT for the \"snail\" example\n",
        "            # So 'PSRN_gt', 'PSNR_gt_sm' make no sense\n",
        "            print ('Iteration %05d    Loss %f   RMSE_LR: %f   RMSE_LR_avg: %f RMSE_HR: %f  RMSE_HR_avg: %f' % (i, total_loss.item(), RMSE_LR, RMSE_LR_avg, RMSE_HR, RMSE_HR_avg), '\\r', end='')\n",
        "            if  PLOT and i % show_every == 0:\n",
        "                out_LR_np = torch_to_np(out_LR)\n",
        "                out_avg_np = torch_to_np(out_avg)\n",
        "\n",
        "                out_LR_np = np.clip(out_LR_np, 0, 1)\n",
        "                out_avg_np = np.clip(out_avg_np, 0, 1)\n",
        "                \n",
        "                f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(10,10))\n",
        "                ax1.imshow(np.stack((out_LR_np[2,:,:],out_LR_np[1,:,:],out_LR_np[0,:,:]),2))\n",
        "                ax2.imshow(np.stack((out_avg_np[2,:,:],out_avg_np[1,:,:],out_avg_np[0,:,:]),2))\n",
        "                ax3.imshow(np.stack((A_true_np[2,:,:],A_true_np[1,:,:],A_true_np[0,:,:]),2))\n",
        "                plt.show()\n",
        "    \n",
        "            i += 1\n",
        "        \n",
        "            return total_loss\n",
        "        \n",
        "        p11 = get_params(OPT_OVER, net1, net_input1)\n",
        "        optimize(OPTIMIZER1, p11, closure1, LR1, num_iter1)"
      ],
      "metadata": {
        "id": "EehS5ybIPakU",
        "outputId": "dd033fec-4d5f-4e81-913c-dda5ba24abf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.083172602094468\n",
            "CAE_AbEst(\n",
            "  (conv1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (1): Concat(\n",
            "        (0): Sequential(\n",
            "          (1): Sequential(\n",
            "            (0): ReflectionPad2d((0, 0, 0, 0))\n",
            "            (1): Conv2d(3, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (1): Sequential(\n",
            "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "            (1): Conv2d(3, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "          )\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (4): Sequential(\n",
            "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "            (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "          (7): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "        )\n",
            "      )\n",
            "      (2): BatchNorm2d(260, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(260, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "      )\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (6): Sequential(\n",
            "        (0): ReflectionPad2d((0, 0, 0, 0))\n",
            "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (9): Sequential(\n",
            "        (0): ReflectionPad2d((0, 0, 0, 0))\n",
            "        (1): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (10): Softmax(dim=None)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Number of params: 1265699\n",
            "Starting optimization with ADAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "  0%|          | 0/5 [00:14<?, ?it/s]\n",
            "  0%|          | 0/4 [00:14<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6b8f131a0a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mp11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPT_OVER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_input1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPTIMIZER1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/UnDIP/utils/common_utils.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(optimizer_type, parameters, closure, LR, num_iter)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moptimizer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RMSprop'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6b8f131a0a80>\u001b[0m in \u001b[0;36mclosure1\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m            \u001b[0;31m# out_HR_avg=out_HR_avg.view((1,p1,nr1,nc1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mout_HR_avg_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_HR_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mRMSE_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_true_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_LR_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mRMSE_LR_avg\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_true_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_avg_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mRMSE_HR\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_np_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_HR_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compare_mse' is not defined"
          ]
        }
      ]
    }
  ]
}